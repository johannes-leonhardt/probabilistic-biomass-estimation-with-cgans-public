{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cwgan\n",
    "import dataset as dst\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (12, 12)})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "print(\"Using CUDA?\", torch.cuda.is_available())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETTINGS, PRELIMINARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_project = pathlib.Path(os.getcwd()).parent\n",
    "\n",
    "data_path = os.path.join(path_to_project, 'data')\n",
    "result_path = os.path.join(path_to_project, 'results', 'cgan', datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "figure_path = os.path.join(result_path, 'figures')\n",
    "model_path = os.path.join(result_path, 'models')\n",
    "\n",
    "try:\n",
    "    os.mkdir(result_path)\n",
    "    os.mkdir(figure_path)\n",
    "    os.mkdir(model_path)\n",
    "except FileExistsError:\n",
    "    print(\"The result directory already exists. Its contents may be overwritten!\")\n",
    "\n",
    "print(\"Results are being saved to\", result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'PATCH_SIZE': 64,\n",
    "    'BATCH_SIZE' : 128,\n",
    "\n",
    "    'LEARNING_RATE_PT' : 5e-5,\n",
    "    'LOSS_FUNC_PT' : nn.MSELoss(),\n",
    "    'ITS_PT' : 2000 + 1,\n",
    "\n",
    "    'LEARNING_RATE' : 1e-5,\n",
    "    'CRITIC_ITERATIONS' : 5,\n",
    "    'WEIGHT_CLIP' : 0.01,\n",
    "    'ITS_WU' : 8000 + 1,\n",
    "    'ENSEMBLE_SIZE' : 10,\n",
    "    'ITS_PER_CYCLE' : 1000 + 1,\n",
    "    'FINE_TUNING' : False\n",
    "}\n",
    "\n",
    "with open(os.path.join(result_path, 'params.txt'), \"w\") as file:\n",
    "    print(PARAMS, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'training'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "validation_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'validation'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "testing_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'testing'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "testing_ds.show(idx)\n",
    "plt.savefig(os.path.join(figure_path, \"obs_bm.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = cwgan.Generator()\n",
    "\n",
    "opt_PT = optim.RMSprop(G.parameters(), lr=PARAMS['LEARNING_RATE_PT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETERMINISTIC PRE-TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_PT = time.time()\n",
    "\n",
    "print(\"--- PRE-TRAINING ---\")\n",
    "\n",
    "min_rmse = np.inf\n",
    "\n",
    "rmse_log = []\n",
    "uce_log = []\n",
    "\n",
    "for it in tqdm(range(PARAMS['ITS_PT'])):\n",
    "\n",
    "    # Training\n",
    "    l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "    loss = G.pretraining_iteration(l, x, loss_func=PARAMS['LOSS_FUNC_PT'], optimizer=opt_PT)\n",
    "\n",
    "    #Validation\n",
    "    if it % 100 == 0:\n",
    "        rmse_pt, uce_pt = cwgan.evaluate_net_on_ds(G, validation_ds)\n",
    "        rmse_log.append(rmse_pt)\n",
    "        uce_log.append(uce_pt)\n",
    "\n",
    "        if rmse_pt < min_rmse:\n",
    "            torch.save(G.state_dict(), os.path.join(model_path, 'pretrain_G.pt'))\n",
    "            \n",
    "G.load_state_dict(torch.load(os.path.join(model_path, 'pretrain_G.pt')))\n",
    "\n",
    "stop_PT = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE AND SHOW SAMPLE RESULT FROM PRE-TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_pt_val, uce_pt_val = cwgan.evaluate_net_on_ds(G, validation_ds)\n",
    "rmse_pt_tst, uce_pt_tst = cwgan.evaluate_net_on_ds(G, testing_ds)\n",
    "\n",
    "l, x = testing_ds.get_full(idx)\n",
    "x = dst.unnormalize_x(x)\n",
    "\n",
    "G.apply(l, n_samples=4, fig=True, x=x)\n",
    "plt.savefig(os.path.join(figure_path, \"sample_ests_pt.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE CWGAN DISCRIMINATOR AND OPTIMIZERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = cwgan.Discriminator()\n",
    "\n",
    "opt_G = optim.RMSprop(G.parameters(), lr=PARAMS['LEARNING_RATE'])\n",
    "opt_D = optim.RMSprop(D.parameters(), lr=PARAMS['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CWGAN WARMUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_warmup = time.time()\n",
    "\n",
    "print(\"--- WARMUP ---\")\n",
    "\n",
    "min_rmse = np.inf\n",
    "min_uce = np.inf\n",
    "\n",
    "for it in tqdm(range(PARAMS['ITS_WU'])):\n",
    "\n",
    "    # Discriminator training\n",
    "    for i in range(PARAMS['CRITIC_ITERATIONS']):\n",
    "        l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "        loss_D = D.training_iteration(l, x, G, optimizer=opt_D, weight_clip=PARAMS['WEIGHT_CLIP'])\n",
    "\n",
    "    # Generator training\n",
    "    l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "    loss_G = G.training_iteration(l, D, optimizer=opt_G)\n",
    "\n",
    "    # Validation\n",
    "    if it % 100 == 0:\n",
    "        rmse, uce = cwgan.evaluate_net_on_ds(G, validation_ds)\n",
    "        rmse_log.append(rmse)\n",
    "        uce_log.append(uce)\n",
    "\n",
    "        if uce < min_uce:\n",
    "            torch.save(G.state_dict(), os.path.join(model_path, 'warmup_G.pt'))\n",
    "            torch.save(opt_G.state_dict(), os.path.join(model_path, 'warmup_opt_G.pt'))\n",
    "            torch.save(D.state_dict(), os.path.join(model_path, 'warmup_D.pt'))\n",
    "            torch.save(opt_D.state_dict(), os.path.join(model_path, 'warmup_opt_D.pt'))\n",
    "            min_rmse, min_uce = rmse, uce\n",
    "\n",
    "G.load_state_dict(torch.load(os.path.join(model_path, 'warmup_G.pt')))\n",
    "opt_G.load_state_dict(torch.load(os.path.join(model_path, 'warmup_opt_G.pt')))\n",
    "D.load_state_dict(torch.load(os.path.join(model_path, 'warmup_D.pt')))\n",
    "opt_D.load_state_dict(torch.load(os.path.join(model_path, 'warmup_opt_D.pt')))\n",
    "\n",
    "stop_warmup = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE AND SHOW SAMPLE RESULT FROM WARMUP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_wu_val, uce_wu_val = cwgan.evaluate_net_on_ds(G, validation_ds)\n",
    "rmse_wu_tst, uce_wu_tst = cwgan.evaluate_net_on_ds(G, testing_ds)\n",
    "\n",
    "l, x = testing_ds.get_full(idx)\n",
    "x = dst.unnormalize_x(x)\n",
    "\n",
    "G.apply(l, n_samples=4, fig=True, x=x)\n",
    "plt.savefig(os.path.join(figure_path, \"sample_ests_wu.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE SCHEDULERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_G = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt_G, PARAMS['ITS_PER_CYCLE'])\n",
    "scheduler_D = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt_D, PARAMS['ITS_PER_CYCLE'] * PARAMS['CRITIC_ITERATIONS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CWGAN ENSEMBLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ens = time.time()\n",
    "\n",
    "print(\"--- ENSEMBLES ---\")\n",
    "\n",
    "for i in range(PARAMS['ENSEMBLE_SIZE']):\n",
    "\n",
    "    print(f\"Ensemble {i}\")\n",
    "\n",
    "    min_rmse = np.inf\n",
    "    min_uce = np.inf\n",
    "\n",
    "    for it in tqdm(range(PARAMS['ITS_PER_CYCLE'])):\n",
    "\n",
    "        # Discriminator training\n",
    "        for _ in range(PARAMS['CRITIC_ITERATIONS']):\n",
    "            l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "            loss_D = D.training_iteration(l, x, G, optimizer=opt_D, scheduler=scheduler_D, weight_clip=PARAMS['WEIGHT_CLIP'])\n",
    "\n",
    "        # Generator training\n",
    "        l, _ = testing_ds.get_batch(PARAMS['BATCH_SIZE']) if PARAMS['FINE_TUNING'] else training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "        loss_G = G.training_iteration(l, D, optimizer=opt_G, scheduler=scheduler_G)\n",
    "\n",
    "        if it % 100 == 0:\n",
    "            rmse, uce = cwgan.evaluate_net_on_ds(G, validation_ds)\n",
    "            rmse_log.append(rmse)\n",
    "            uce_log.append(uce)\n",
    "\n",
    "            if uce < min_uce:\n",
    "                torch.save(G.state_dict(), os.path.join(model_path, f\"ens_{i}_G.pt\"))\n",
    "                min_rmse, min_uce = rmse, uce\n",
    "\n",
    "    l, x = testing_ds.get_full(idx)\n",
    "    x = dst.unnormalize_x(x)\n",
    "    G.apply(l, n_samples=4, fig=True, x=x)\n",
    "    plt.savefig(os.path.join(figure_path, f\"sample_ests_{i}.png\"))\n",
    "\n",
    "stop_ens = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot((np.arange(len(rmse_log)) + 1) * 100, np.array(rmse_log), 'g-')\n",
    "ax2.plot((np.arange(len(uce_log)) + 1) * 100, np.array(uce_log), 'b-')\n",
    "ax1.set_xlabel('Training Iteration')\n",
    "ax1.set_ylabel('RMSE', color='g')\n",
    "ax2.set_ylabel('UCE', color='b')\n",
    "\n",
    "plt.savefig(os.path.join(figure_path, f\"losscurve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_rmses_val, ensemble_uces_val, rmses_val, uces_val = cwgan.evaluate_ensemble_on_ds(model_path, validation_ds, module=cwgan.Generator, fig=False)\n",
    "ensemble_rmses_tst, ensemble_uces_tst, rmses_tst, uces_tst = cwgan.evaluate_ensemble_on_ds(model_path, testing_ds, module=cwgan.Generator, fig=True)\n",
    "plt.savefig(os.path.join(figure_path, \"calib_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, 'res.txt'), \"w\") as file:\n",
    "    print(\"Pre-training took\", stop_PT-start_PT, \"seconds.\", file=file)\n",
    "    print(f\"Validation after pre-training - RMSE: {rmse_pt_val}, UCE: {uce_pt_val}\", file=file)\n",
    "    print(f\"Test after pre-training - RMSE: {rmse_pt_tst}, UCE: {uce_pt_tst}\", file=file)\n",
    "    print(\"Adversarial training took\", (stop_warmup-start_warmup) + (stop_ens-start_ens), \"seconds.\", file=file)\n",
    "    print(f'Validation after warmup - RMSE: {rmse_wu_val}, UCE: {uce_wu_val}', file=file)\n",
    "    print(f'Testing after warmup - RMSE: {rmse_wu_tst}, UCE: {uce_wu_tst}', file=file)\n",
    "    print(f\"Final Ensemble Validation - Ensemble RMSE: {np.mean(ensemble_rmses_val)}, Ensemble UCE: {np.mean(ensemble_uces_val)}, Individual RMSE: {np.mean(rmses_val)}, Individual UCE: {np.mean(uces_val)}\", file=file)\n",
    "    print(f\"Final Ensemble Test - Ensemble RMSE: {np.mean(ensemble_rmses_tst)}, Ensemble UCE: {np.mean(ensemble_uces_tst)}, Individual RMSE: {np.mean(rmses_tst)}, Individual UCE: {np.mean(uces_tst)}\", file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('agb_cgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a8915b0417a0690f49903a99daf833c45a0b5865c61e8bfe5d61e124b6dbc1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

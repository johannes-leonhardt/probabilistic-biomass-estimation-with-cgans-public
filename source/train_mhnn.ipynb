{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mhnn\n",
    "import dataset as dst\n",
    "\n",
    "plt.rcParams.update({'figure.figsize': (12, 12)})\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "print(\"Using CUDA?\", torch.cuda.is_available())\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETTINGS, PRELIMINARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_project = pathlib.Path(os.getcwd()).parent\n",
    "\n",
    "data_path = os.path.join(path_to_project, 'data')\n",
    "result_path = os.path.join(path_to_project, 'results', 'mhnn', datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "figure_path = os.path.join(result_path, 'figures')\n",
    "model_path = os.path.join(result_path, 'models')\n",
    "\n",
    "try:\n",
    "    os.mkdir(result_path)\n",
    "    os.mkdir(figure_path)\n",
    "    os.mkdir(model_path)\n",
    "except FileExistsError:\n",
    "    print(\"The result directory already exists. Its contents may be overwritten!\")\n",
    "\n",
    "print(\"Results are being saved to\", result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'PATCH_SIZE': 64,\n",
    "    'BATCH_SIZE': 128,\n",
    "    'LEARNING_RATE': 5e-5,\n",
    "    'ITS_WU': 5000 + 1,\n",
    "    'ENSEMBLE_SIZE': 10,\n",
    "    'ITS_PER_CYCLE': 1000 + 1\n",
    "}\n",
    "\n",
    "with open(os.path.join(result_path, 'params.txt'), \"w\") as log:\n",
    "    print(PARAMS, file=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'training'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "validation_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'validation'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "testing_ds = dst.AgbDataset(\n",
    "    os.path.join(data_path, 'testing'), \n",
    "    patch_size = PARAMS['PATCH_SIZE']\n",
    ")\n",
    "\n",
    "idx = 0\n",
    "\n",
    "testing_ds.show(idx)\n",
    "plt.savefig(os.path.join(figure_path, \"obs_bm.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE NETWORK AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mhnn.MHNN()\n",
    "\n",
    "opt = optim.RMSprop(net.parameters(), lr=PARAMS['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARMUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_warmup = time.time()\n",
    "\n",
    "print(\"--- WARMUP ---\")\n",
    "\n",
    "min_rmse = np.inf\n",
    "min_uce = np.inf\n",
    "\n",
    "rmse_log = []\n",
    "uce_log = []\n",
    "\n",
    "for it in tqdm(range(PARAMS['ITS_WU'])):\n",
    "\n",
    "    l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "\n",
    "    # Training\n",
    "    loss = net.training_iteration(l, x, optimizer=opt)\n",
    "\n",
    "    # Validation\n",
    "    if it % 100 == 0:\n",
    "        rmse, uce = mhnn.evaluate_net_on_ds(net, validation_ds)\n",
    "        rmse_log.append(rmse)\n",
    "        uce_log.append(uce)\n",
    "\n",
    "        if uce < min_uce:\n",
    "            torch.save(net.state_dict(), os.path.join(model_path, 'warmup_net.pt'))\n",
    "            min_rmse, min_uce = rmse, uce\n",
    "\n",
    "net.load_state_dict(torch.load(os.path.join(model_path, 'warmup_net.pt')))\n",
    "\n",
    "stop_warmup = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE AND SHOW RESULT ON WARMUP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_wu_val, uce_wu_val = mhnn.evaluate_net_on_ds(net, validation_ds)\n",
    "rmse_wu_tst, uce_wu_tst = mhnn.evaluate_net_on_ds(net, testing_ds)\n",
    "\n",
    "l, x = testing_ds.get_full(idx)\n",
    "x = dst.unnormalize_x(x)\n",
    "\n",
    "net.apply(l, fig=True, x=x)\n",
    "plt.savefig(os.path.join(figure_path, \"est_wu.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INITIALIZE SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, PARAMS['ITS_PER_CYCLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENSEMBLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ens = time.time()\n",
    "\n",
    "print(\"--- ENSEMBLES ---\")\n",
    "\n",
    "plt.figure()\n",
    "for i in range(PARAMS['ENSEMBLE_SIZE']):\n",
    "\n",
    "    print(f\"Ensemble {i}\")\n",
    "\n",
    "    min_rmse = np.inf\n",
    "    min_uce = np.inf\n",
    "\n",
    "    for it in tqdm(range(PARAMS['ITS_PER_CYCLE'])):\n",
    "\n",
    "        # Training\n",
    "        l, x = training_ds.get_batch(PARAMS['BATCH_SIZE'])\n",
    "        loss = net.training_iteration(l, x, optimizer=opt, scheduler=scheduler)\n",
    "\n",
    "        # Validation\n",
    "        if it % 100 == 0:\n",
    "            rmse, uce = mhnn.evaluate_net_on_ds(net, validation_ds)\n",
    "            rmse_log.append(rmse)\n",
    "            uce_log.append(uce)\n",
    "\n",
    "            if uce < min_uce:\n",
    "                torch.save(net.state_dict(), os.path.join(model_path, f\"ens_{i}_net.pt\"))\n",
    "                min_rmse, min_uce = rmse, uce\n",
    "\n",
    "    l, x = testing_ds.get_full(idx)\n",
    "    x = dst.unnormalize_x(x)\n",
    "    net.apply(l, fig=True, x=x)\n",
    "    plt.savefig(os.path.join(figure_path, f\"est_{i}.png\"))\n",
    "\n",
    "stop_ens = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot((np.arange(len(rmse_log)) + 1) * 100, np.array(rmse_log), 'g-')\n",
    "ax2.plot((np.arange(len(uce_log)) + 1) * 100, np.array(uce_log), 'b-')\n",
    "ax1.set_xlabel('Training Iteration')\n",
    "ax1.set_ylabel('RMSE', color='g')\n",
    "ax2.set_ylabel('UCE', color='b')\n",
    "\n",
    "plt.savefig(os.path.join(figure_path, f\"losscurve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE ENSEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_rmses_val, ensemble_uces_val, rmses_val, uces_val = mhnn.evaluate_ensemble_on_ds(model_path, validation_ds, module=mhnn.MHNN, fig=False)\n",
    "ensemble_rmses_tst, ensemble_uces_tst, rmses_tst, uces_tst = mhnn.evaluate_ensemble_on_ds(model_path, testing_ds, module=mhnn.MHNN, fig=True)\n",
    "plt.savefig(os.path.join(figure_path, \"calib_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_path, 'res.txt'), \"w\") as file:\n",
    "    print(\"Training took\", (stop_warmup-start_warmup) + (stop_ens-start_ens), \"seconds.\", file=file)\n",
    "    print(f'Validation after warmup - RMSE: {rmse_wu_val}, UCE: {uce_wu_val}', file=file)\n",
    "    print(f'Testing after warmup - RMSE: {rmse_wu_tst}, UCE: {uce_wu_tst}', file=file)\n",
    "    print(f\"Final Ensemble Validation - Ensemble RMSE: {np.mean(ensemble_rmses_val)}, Ensemble UCE: {np.mean(ensemble_uces_val)}, Individual RMSE: {np.mean(rmses_val)}, Individual UCE: {np.mean(uces_val)}\", file=file)\n",
    "    print(f\"Final Ensemble Test - Ensemble RMSE: {np.mean(ensemble_rmses_tst)}, Ensemble UCE: {np.mean(ensemble_uces_tst)}, Individual RMSE: {np.mean(rmses_tst)}, Individual UCE: {np.mean(uces_tst)}\", file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('agb_cgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a8915b0417a0690f49903a99daf833c45a0b5865c61e8bfe5d61e124b6dbc1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
